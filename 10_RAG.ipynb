{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4192a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_ollama import OllamaEmbeddings, ChatOllama\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from langchain.agents import create_agent\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain.tools import tool\n",
    "from langgraph.checkpoint.memory import MemorySaver \n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "PDF_DIR = os.getenv(\"PDF_DIR\")\n",
    "\n",
    "COLLECTION_NAME=os.getenv(\"COLLECTION_NAME\")\n",
    "\n",
    "OLLAMA_MODEL=os.getenv(\"OLLAMA_MODEL\")\n",
    "\n",
    "PERSIST_DIR=os.getenv(\"PERSIST_DIR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7945539f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating / updating Chroma collection...\n"
     ]
    }
   ],
   "source": [
    "def stable_id(text: str, meta_key: str) -> str:\n",
    "    \"\"\"Create a stable, de-duplicated ID for each chunk.\"\"\"\n",
    "    h = hashlib.sha256()\n",
    "\n",
    "    h.update((text + \"|\" + meta_key).encode(\"utf-8\"))\n",
    "\n",
    "    return h.hexdigest()\n",
    "\n",
    "def load_pdfs(pdf_dir: str) -> List[Document]:\n",
    "    docs: List[Document] = []\n",
    "\n",
    "    for pdf_path in glob.glob(os.path.join(pdf_dir, \"**/*.pdf\"), recursive=True):\n",
    "        loader = PyPDFLoader(pdf_path)\n",
    "       \n",
    "        page_docs = loader.load()\n",
    "        \n",
    "        for d in page_docs:\n",
    "            d.metadata.setdefault(\"source\", pdf_path)\n",
    "\n",
    "        docs.extend(page_docs)\n",
    "\n",
    "    return docs\n",
    "\n",
    "def chunk_docs(docs: List[Document]) -> List[Document]:\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=800,      \n",
    "        chunk_overlap=120,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    "    )\n",
    "\n",
    "    return splitter.split_documents(docs)\n",
    "\n",
    "print(\"Creating / updating Chroma collection...\")\n",
    "\n",
    "vectordb = Chroma(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    embedding_function=OllamaEmbeddings(model=OLLAMA_MODEL),\n",
    "    persist_directory=PERSIST_DIR,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ce7d340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_save_embeddings_to_db():\n",
    "    Path(PERSIST_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(\"Loading PDFs...\")\n",
    "\n",
    "    raw_docs = load_pdfs(PDF_DIR)\n",
    "\n",
    "    if not raw_docs:\n",
    "        print(f\"No PDFs found in the directory.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Loaded {len(raw_docs)} page docs. Chunking...\")\n",
    "\n",
    "    docs = chunk_docs(raw_docs)\n",
    "\n",
    "    print(f\"Produced {len(docs)} chunks.\")\n",
    "\n",
    "    # Avoid duplicating chunks on re-runs by providing stable IDs\n",
    "    ids = []\n",
    "\n",
    "    for d in docs:\n",
    "        # include source + page + start offset to reduce collisions\n",
    "        mk = f\"{d.metadata.get('source','')}-{d.metadata.get('page',-1)}-{len(d.page_content)}\"\n",
    "        \n",
    "        ids.append(stable_id(d.page_content, mk))\n",
    "\n",
    "    # Upsert into Chroma\n",
    "    vectordb.add_documents(documents=docs, ids=ids)\n",
    "\n",
    "    print(\"documents added to the collection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99423f35",
   "metadata": {},
   "source": [
    "# Loading docs and save embeddings to the DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38662f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PDFs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 151 0 (offset 0)\n",
      "Ignoring wrong pointing object 286 0 (offset 0)\n",
      "Ignoring wrong pointing object 440 0 (offset 0)\n",
      "Ignoring wrong pointing object 502 0 (offset 0)\n",
      "Ignoring wrong pointing object 523 0 (offset 0)\n",
      "Ignoring wrong pointing object 555 0 (offset 0)\n",
      "Ignoring wrong pointing object 558 0 (offset 0)\n",
      "Ignoring wrong pointing object 566 0 (offset 0)\n",
      "Ignoring wrong pointing object 587 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 47 page docs. Chunking...\n",
      "Produced 90 chunks.\n",
      "documents added to the collection\n"
     ]
    }
   ],
   "source": [
    "load_and_save_embeddings_to_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f78e67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retreiver config\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def retrieve_context(query:str):\n",
    "    \"\"\"Search for the info related ot the given query in the vector database\"\"\"\n",
    "    \n",
    "    try:\n",
    "        docs = retriever.invoke(query)\n",
    "\n",
    "        # print(f\"\\nTop {len(docs)} chunks:\")\n",
    "\n",
    "        # for i, doc in enumerate(docs):\n",
    "        #     src = doc.metadata.get(\"source\", \"unknown\")\n",
    "        #     page = doc.metadata.get(\"page\", \"?\")\n",
    "        #     print(f\"\\n[{i}] {src} (page {page})\\n{doc.page_content[:500]}...\")\n",
    "\n",
    "        content = \"\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "        return content\n",
    "    except Exception as e:\n",
    "        print(f\"Error in retrieving the information:{e}\")\n",
    "\n",
    "        return f\"Error in retrieving the information {e}. Please try again.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f09412",
   "metadata": {},
   "source": [
    "# Creating the agent with RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2921e174",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model = ChatOllama(model=\"llama3.2\", temperature=0.4, repeat_penalty=1.3)\n",
    "\n",
    "agent_executor = create_agent(model=llm_model, \n",
    "                            tools=[retrieve_context], \n",
    "                            checkpointer=MemorySaver(),\n",
    "                            system_prompt = \"\"\"\n",
    "                                You are a **knowledge-check assistant** for the Keerti Gen-AI course with random concepts.\n",
    "\n",
    "                                STRICT RULES:\n",
    "                                1. You may use ONLY the `retrieve_context` tool — and ONLY when you need background info\n",
    "                                before writing a question. Never use it after a user answers.\n",
    "                                2. When grading, DO NOT call any tool or emit JSON / code / <|python_tag|>. \n",
    "                                Simply say whether the answer is correct or wrong and add a one-sentence explanation.\n",
    "                                3. Always generate ONE multiple-choice question (A–D) at a time.\n",
    "                                4. Wait for the user's answer, then evaluate it.\n",
    "                                5. After evaluating, pick another concept, call `retrieve_context` with that concept,\n",
    "                                and generate the next question.\n",
    "                                6. Use plain English text only — no JSON, no special tags.\n",
    "                                \"\"\"\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14db98cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_last_ai(response):\n",
    "    response[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9582f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_quiz():\n",
    "    print(\"Keerti Gen-AI Quiz • type 'exit' to quit\")\n",
    "    print(\"Assistant: Ready! I’ll pick a concept and generate the first question.\")\n",
    "\n",
    "    config = {\"configurable\": {\"thread_id\": \"keerti-genai-quiz\"}}\n",
    "\n",
    "    first_turn = agent_executor.invoke(\n",
    "                        {\"messages\": [HumanMessage(content=\"Start the quiz.\")]}, \n",
    "                        config=config)\n",
    "    \n",
    "    format_last_ai(first_turn)\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"Your option: \").strip()\n",
    "\n",
    "        if user_input.lower() in {\"exit\", \"quit\"}:\n",
    "            print(\"Assistant: Great session! See you next time.\")\n",
    "            break\n",
    "        \n",
    "        print(user_input)\n",
    "\n",
    "        user_message = HumanMessage(content=f\"My answer is: {user_input}. When grading, DO NOT call any tool or emit JSON / code / <|python_tag|>. Simply say whether the answer is correct or wrong and add a one-sentence explanation. Generate next question with 4 options.\")\n",
    "\n",
    "        # user_message.pretty_print()\n",
    "\n",
    "        turn = agent_executor.invoke(\n",
    "                {\"messages\": [user_message]}, \n",
    "                config=config)\n",
    "\n",
    "        format_last_ai(turn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f20fcb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keerti Gen-AI Quiz • type 'exit' to quit\n",
      "Assistant: Ready! I’ll pick a concept and generate the first question.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Let's start the quiz.\n",
      "\n",
      "Here is your first question:\n",
      "\n",
      "What is a key purpose of callbacks in Keras?\n",
      "\n",
      "A) To train models with more data\n",
      "B) To enhance control over the training process and automate tasks like saving the best model or adjusting learning rates.\n",
      "C) To improve model performance by using different optimization algorithms\n",
      "D) To reduce the number of parameters in neural networks\n",
      "\n",
      "Please choose your answer.\n",
      "D\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Wrong\n",
      "The best answer is B. A callback's primary purpose in Keras is to enhance control over the training process, allowing for tasks like saving the best model or adjusting learning rates.\n",
      "\n",
      "Here's your next question:\n",
      "\n",
      "What type of data does a Generative Adversarial Network (GAN) generate?\n",
      "\n",
      "A) Realistic images and videos\n",
      "B) Fake data that resembles real data but is not actual reality\n",
      "C) Abstract art pieces with no relation to realism\n",
      "D) 3D models for product design\n",
      "B\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Correct\n",
      "The best answer is B. A Generative Adversarial Network (GAN) generates fake data that resembles real data but is not actual reality.\n",
      "\n",
      "Here's your next question:\n",
      "\n",
      "What does the term \"Batch Size\" refer to in neural networks?\n",
      "\n",
      "{\"name\": \"retrieve_context\", \"parameters\": {\"query\": \"batch size meaning\"}}\n",
      "records use to train the model at an instance\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Wrong\n",
      "The best answer is \"Number of training samples processed before updating weights.\" Batch size refers to the number of examples (records) used to train a model at each instance.\n",
      "\n",
      "Here's your next question:\n",
      "\n",
      "What does Keras' high-level API allow for?\n",
      "\n",
      "A) Only building neural networks from scratch with low-level code\n",
      "B) Building complex models using only low-level APIs and manual optimization techniques\n",
      "C) High-level, user-friendly interface for quickly creating and training deep learning models\n",
      "D) Limited control over the underlying machine learning algorithms\n",
      "C\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Correct\n",
      "The best answer is C. Keras' high-level API allows for building complex models using user-friendly interfaces, making it easier to quickly create and train deep learning models.\n",
      "\n",
      "Here's your next question:\n",
      "\n",
      "What are the primary goals of a Generative Adversarial Network (GAN)?\n",
      "\n",
      "A) To classify data into different categories\n",
      "B) To generate new images that resemble existing ones in the training dataset\n",
      "C) To compress images for storage purposes\n",
      "D) To recognize patterns within datasets\n",
      "A\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Wrong\n",
      "The best answer is B. The primary goals of a Generative Adversarial Network (GAN) are to generate new images that resemble existing ones in the training dataset.\n",
      "\n",
      "Here's your next question:\n",
      "\n",
      "What does \"Learning Rate\" control in neural networks?\n",
      "\n",
      "{\"name\": \"retrieve_context\", \"parameters\": {\"query\": \"learning rate meaning\"}}\n",
      "Assistant: Great session! See you next time.\n"
     ]
    }
   ],
   "source": [
    "start_quiz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5178727",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simple-chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
